{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from scipy.io import savemat\n",
    "from datetime import datetime\n",
    "\n",
    "import pdb\n",
    "\n",
    "import psycopg2\n",
    "import sqlite3\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "sqliteDb = \"/storage/kuusela-stein-intrep-profiles/jg-pchip_profiles.db\"\n",
    "tableName = 'pchip'\n",
    "conn = sqlite3.connect(sqliteDb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x7fe27b499260>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.execute('''DROP TABLE IF EXISTS {};'''.format(tableName))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution failed on sql 'SELECT * FROM pchip LIMIT 10;': no such table: pchip\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    smdf = pd.read_sql_query('SELECT * FROM {} LIMIT 10;'.format(tableName), conn)\n",
    "except Exception as err:\n",
    "    print(err)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./JG-profiles-10.csv\n"
     ]
    }
   ],
   "source": [
    "#files = glob('/storage/kuusela-stein-intrep-profiles/iTempData_pres_50*.0.csv')\n",
    "files = glob('./JG-profiles-10.csv')\n",
    "def convert_csv_to_sqlite(files):\n",
    "    for file in files:\n",
    "        print(file)\n",
    "        tdf = pd.read_csv(file, index_col=0)\n",
    "        tdf = tdf.drop('psal', axis=1)\n",
    "        psalFile = file.replace('Temp', 'Psal')\n",
    "        sdf = pd.read_csv(psalFile, index_col=0)\n",
    "        df = pd.merge(tdf, sdf[['profile_id', 'pres', 'psal']], how='outer', on=['profile_id', 'pres'])\n",
    "        df = df.drop_duplicates(subset=['profile_id', 'pres'])\n",
    "        df = df[df.lat != -89]\n",
    "        df.to_sql(tableName, conn, if_exists='append', index=False)\n",
    "def convert_jg_csv_to_sqlite(files):\n",
    "    for file in files:\n",
    "        print(file)\n",
    "        df = pd.read_csv(file, index_col=0)\n",
    "        df = df.drop_duplicates(subset=['profile_id', 'pres'])\n",
    "        df = df[df.lat != -89]\n",
    "        df.to_sql(tableName, conn, if_exists='append', index=False)\n",
    "convert_jg_csv_to_sqlite(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_pressure_level_df(conn, presLevel=10, tableName='pchip'):\n",
    "    try:\n",
    "        queryStr = 'SELECT * FROM {0} WHERE pres = {1};'.format(tableName, presLevel)\n",
    "        df = pd.read_sql_query(queryStr, conn)\n",
    "        df = df.drop_duplicates(subset=['profile_id', 'pres'])\n",
    "        #df = df[df['position_qc'].isin([1,2])]\n",
    "        #df = df[df['date_qc'].isin([1,2])]\n",
    "        df = df[(df['lat']!=0) & (df['lon']!=0)]\n",
    "    except Exception as err:\n",
    "        print(err)\n",
    "        raise(err)\n",
    "    return df\n",
    "\n",
    "def convert_lon(lon):\n",
    "    '''\n",
    "    converts from [-180, 180] to [20, 380]\n",
    "    '''\n",
    "    if lon < 20:\n",
    "        lon += 360\n",
    "    return lon\n",
    "\n",
    "def make_dict_for_mat(df, obs, minYear, maxYear):\n",
    "    df = df.dropna(how='any',axis=0, subset=[obs])\n",
    "    df = df.drop_duplicates(subset=['profile_id'])\n",
    "    df = df.drop_duplicates(subset=['lat', 'lon']) # need to have lat long be unique when making mask\n",
    "    df = df.sort_values(by=['lat', 'lon']) # sorting columns needed for binary search\n",
    "    df.date = pd.to_datetime(df.date.values)\n",
    "    df['year'] = df.date.apply(lambda x: x.year)\n",
    "    df['month'] = df.date.apply(lambda x: x.month)\n",
    "    df = df[(df['year'] >= minYear) & (df['year'] <= maxYear)]\n",
    "    df.date = df.date.apply(lambda x: x.strftime(\"%d-%b-%Y %H:%M:%S\"))\n",
    "    df['lon'] = df['lon'].apply(lambda lon: convert_lon(lon))\n",
    "    df = df[df[obs] != -999]\n",
    "    \n",
    "    df = df[[obs, 'profile_id', 'date', 'year', 'month', 'lat', 'lon']]\n",
    "    df.columns = ['obsProf', 'profFloatIDAggrSel', 'profJulDayAggrSel',\n",
    "                  'profYearAggrSel', 'profMonthAggrSel', 'profLatAggrSel', 'profLongAggrSel']\n",
    "    a_dict = {col_name : df[col_name].values for col_name in df.columns.values}\n",
    "\n",
    "    a_dict['profFloatIDAggrSel'] = a_dict['profFloatIDAggrSel'].astype(str)\n",
    "\n",
    "    return a_dict\n",
    "\n",
    "def make_file_name(presLevel, obs, minYear, maxYear, prefix='/storage/kuusela-stein-intrep-profiles/'):\n",
    "    fileName = prefix + 'prof'\n",
    "    fileName += str(obs).capitalize()\n",
    "    fileName += '_at{}dbar'.format(str(presLevel))\n",
    "    fileName += '_{0}_{1}'.format(minYear, maxYear)\n",
    "    fileName += '.mat'\n",
    "    return fileName\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/storage/kuusela-stein-intrep-profiles/profTemp_at10.0dbar_2007_2018.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tyler/anaconda3/envs/argo/lib/python3.6/site-packages/scipy/io/matlab/miobase.py:414: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  arr[empties] = ' '\n"
     ]
    }
   ],
   "source": [
    "minYear=2007\n",
    "maxYear=2018\n",
    "presLevels = [10.0]\n",
    "obs='temp'\n",
    "for presLevel in presLevels:\n",
    "    df = get_pressure_level_df(conn, presLevel)\n",
    "    if df.empty:\n",
    "        print('no presLevel []'.format(presLevel))\n",
    "        continue\n",
    "    presDict = make_dict_for_mat(df, obs, minYear, maxYear)\n",
    "    fileName = make_file_name(presLevel, obs, minYear, maxYear)\n",
    "    print(fileName)\n",
    "\n",
    "    savemat(fileName, presDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['obsProf', 'profFloatIDAggrSel', 'profJulDayAggrSel', 'profYearAggrSel', 'profMonthAggrSel', 'profLatAggrSel', 'profLongAggrSel'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "presDict.keys()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python argo",
   "language": "python",
   "name": "argo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
