{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import pymongo\n",
    "import pdb\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import *\n",
    "from scipy.io import loadmat\n",
    "import os\n",
    "import glob\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_collection(dbName, collectionName, init_collection):\n",
    "    dbUrl = 'mongodb://localhost:27017/'\n",
    "    client = pymongo.MongoClient(dbUrl)\n",
    "    db = client[dbName]\n",
    "    coll = db[collectionName]\n",
    "    coll = init_collection(coll)\n",
    "    return coll\n",
    "\n",
    "def init_grid_collection(coll):\n",
    "    coll.create_index([('date', pymongo.DESCENDING)])\n",
    "    coll.create_index([('pres', pymongo.DESCENDING)])\n",
    "    coll.create_index([('data.lat', pymongo.DESCENDING)])\n",
    "    coll.create_index([('data.lon', pymongo.ASCENDING)])\n",
    "    coll.create_index([('trend', pymongo.DESCENDING)])\n",
    "\n",
    "    return coll\n",
    "\n",
    "def init_param_collection(coll):\n",
    "    coll.create_index([('pres', pymongo.DESCENDING)])\n",
    "    coll.create_index([('data.lon', pymongo.DESCENDING)])\n",
    "    coll.create_index([('data.lat', pymongo.ASCENDING)])\n",
    "    coll.create_index([('param', pymongo.DESCENDING),\n",
    "                       ('trend', pymongo.DESCENDING),\n",
    "                       ('model', pymongo.DESCENDING),\n",
    "                       ('modelParam', pymongo.DESCENDING)])\n",
    "        \n",
    "    return coll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_lon(lon):\n",
    "    '''\n",
    "    Transforms longitude from absolute to -180 to 180 deg\n",
    "    '''\n",
    "    if lon >= 180:\n",
    "        lon -= 360\n",
    "    return lon\n",
    "\n",
    "def make_doc(df, date, trend, presLevel, dataVariable, param, measurement, gridName, units):\n",
    "    '''\n",
    "    Takes df and converts it into a document for mongodb\n",
    "    '''\n",
    "    doc = {}\n",
    "    df = df.rename(index=str, columns={dataVariable: 'value'})\n",
    "    dataDict = df.to_dict(orient='records')\n",
    "    doc['gridName'] = gridName\n",
    "    doc['measurement'] = measurement #temperature or psal\n",
    "    doc['units'] = units # degrees celsius or psu\n",
    "    doc['param'] = param # anomaly or mean\n",
    "    doc['data'] = dataDict \n",
    "    doc['variable'] = dataVariable # ARGO_TEMPERATURE_ANOMALY or ARGO_TEMPERATURE_MEAN or predGrid\n",
    "    doc['date'] = date\n",
    "    doc['pres'] = float(presLevel)\n",
    "    doc['cellsize'] = 1  #  Degree\n",
    "    doc['NODATA_value'] = np.NaN\n",
    "    doc['trend'] = trend\n",
    "    return doc\n",
    "\n",
    "def make_grid_docs(files, gridName, trend, param='anomaly', dataVariable='predGrid'):\n",
    "    docs = []\n",
    "    for file in files:\n",
    "        doc = {}\n",
    "        anomData = loadmat(file)\n",
    "        fa = file.split('/')[-1].split('_')\n",
    "        year = fa[-1].replace('.mat', '')\n",
    "        month = fa[-2]\n",
    "        year_month = year + month\n",
    "        date = datetime.strptime(year_month, '%Y%m')\n",
    "        presLevel = float(fa[-6].replace('at', '').replace('dbar', ''))\n",
    "        latGrid = anomData['latGrid'].flatten()\n",
    "        lonGrid = anomData['longGrid'].flatten()\n",
    "        values = anomData[dataVariable].flatten()\n",
    "        df = pd.DataFrame()\n",
    "        df['lat'] = latGrid\n",
    "        df['lon'] = lonGrid\n",
    "        df['lon'] = df['lon'].apply(lambda lon: transform_lon(lon))\n",
    "        df['value'] = values\n",
    "        \n",
    "        doc = make_doc(df, date, trend, presLevel, dataVariable, param, 'temperature', gridName, 'Degrees Celcius')\n",
    "        docs.append(doc)\n",
    "    return docs\n",
    "\n",
    "def make_param_docs(grids):\n",
    "    docs = []\n",
    "    for pres, measurement, model, trend in grids:\n",
    "        paramFiles = '{0}{1}{2}*.mat'.format(model, trend, measurement)\n",
    "\n",
    "        path = os.path.join(kuuselaBase, pres,\\\n",
    "                                'outliers_removed', trend, 'Results',\\\n",
    "                                'localMLE' + paramFiles)\n",
    "        filename = glob.glob(path) # should be one\n",
    "        print(paramFiles)\n",
    "        if not filename:\n",
    "            print('file not found: {}'.format(path))\n",
    "            continue\n",
    "        print(filename)\n",
    "        paramData = loadmat(filename[0])\n",
    "        if model == 'Space':\n",
    "            modelParams = spaceParams\n",
    "        elif model == 'SpaceTime':\n",
    "            modelParams = spaceTimeParams\n",
    "        else:\n",
    "            raise('modelParams not found')\n",
    "\n",
    "        for modelParam in modelParams:\n",
    "            print(pres, measurement, model, trend, modelParam)\n",
    "            doc = make_param_doc(paramData, modelParam, model, trend, measurement, pres)\n",
    "            docs.append(doc)\n",
    "    return docs\n",
    "\n",
    "def make_param_doc(paramData, modelParam, model, trend, measurement, pres):\n",
    "    values = paramData[modelParam].flatten()\n",
    "    latGrid = paramData['latGrid'].flatten()\n",
    "    lonGrid = paramData['longGrid'].flatten()\n",
    "    gridName = 'ks' + model + measurement + trend\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    df['lat'] = latGrid\n",
    "    df['lon'] = lonGrid\n",
    "    df['lon'] = df['lon'].apply(lambda lon: transform_lon(lon))\n",
    "    df['value'] = values\n",
    "    dataDict = df.to_dict(orient='records')\n",
    "    doc = {}\n",
    "    doc['gridName'] = gridName\n",
    "    doc['model'] = model\n",
    "    doc['param'] = modelParam\n",
    "    doc['units'] = '' #TODO: figure out what to add for units\n",
    "    doc['trend'] = trend\n",
    "    doc['measurement'] = measurement\n",
    "    doc['data'] = dataDict\n",
    "    doc['pres'] = float(pres)\n",
    "    doc['cellsize'] = 1  #  Degree\n",
    "    doc['NODATA_value'] = np.NaN\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make param collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kuuselaBase = os.path.join('/home','tyler','Kuusela-Stein', 'Data', 'Data')\n",
    "pressures = [str(10.0)]\n",
    "measurements = ['Temp']\n",
    "trends = ['Trend', 'NoTrend', 'Trend2']\n",
    "models = ['Space', 'SpaceTime']\n",
    "spaceTimeParams  = ['nResGrid', 'nll', 'sigmaOpt', 'thetaLatOpt', 'thetaLongOpt', 'thetasOpt', 'thetatOpt']\n",
    "spaceParams = ['aOpt', 'latGrid', 'longGrid', 'nResGrid', 'nll', 'sigmaOpt', 'theta1Opt', 'theta2Opt']\n",
    "\n",
    "units = {\n",
    "    'nResGrid': 'number of profiles used',\n",
    "    'nll': 'negative log likilihood',\n",
    "    'sigmaOpt': 'Degrees Celsius',\n",
    "    'thetaLatOpt': 'Degrees',\n",
    "    'thetaLongOpt': 'Degrees',\n",
    "    'thetasOpt': '[]'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpaceTrendTemp*.mat\n",
      "['/home/tyler/Kuusela-Stein/Data/Data/10.0/outliers_removed/Trend/Results/localMLESpaceTrendTemp_at10.0dbar_5_20_02_2007_2018.mat']\n",
      "10.0 Temp Space Trend aOpt\n",
      "10.0 Temp Space Trend latGrid\n",
      "10.0 Temp Space Trend longGrid\n",
      "10.0 Temp Space Trend nResGrid\n",
      "10.0 Temp Space Trend nll\n",
      "10.0 Temp Space Trend sigmaOpt\n",
      "10.0 Temp Space Trend theta1Opt\n",
      "10.0 Temp Space Trend theta2Opt\n",
      "SpaceNoTrendTemp*.mat\n",
      "['/home/tyler/Kuusela-Stein/Data/Data/10.0/outliers_removed/NoTrend/Results/localMLESpaceNoTrendTemp_at10.0dbar_5_20_02_2007_2018.mat']\n",
      "10.0 Temp Space NoTrend aOpt\n",
      "10.0 Temp Space NoTrend latGrid\n",
      "10.0 Temp Space NoTrend longGrid\n",
      "10.0 Temp Space NoTrend nResGrid\n",
      "10.0 Temp Space NoTrend nll\n",
      "10.0 Temp Space NoTrend sigmaOpt\n",
      "10.0 Temp Space NoTrend theta1Opt\n",
      "10.0 Temp Space NoTrend theta2Opt\n",
      "SpaceTrend2Temp*.mat\n",
      "['/home/tyler/Kuusela-Stein/Data/Data/10.0/outliers_removed/Trend2/Results/localMLESpaceTrend2Temp_at10.0dbar_5_20_02_2007_2018.mat']\n",
      "10.0 Temp Space Trend2 aOpt\n",
      "10.0 Temp Space Trend2 latGrid\n",
      "10.0 Temp Space Trend2 longGrid\n",
      "10.0 Temp Space Trend2 nResGrid\n",
      "10.0 Temp Space Trend2 nll\n",
      "10.0 Temp Space Trend2 sigmaOpt\n",
      "10.0 Temp Space Trend2 theta1Opt\n",
      "10.0 Temp Space Trend2 theta2Opt\n",
      "SpaceTimeTrendTemp*.mat\n",
      "['/home/tyler/Kuusela-Stein/Data/Data/10.0/outliers_removed/Trend/Results/localMLESpaceTimeTrendTempMidOcean_5_20_10_02_2007_2018.mat']\n",
      "10.0 Temp SpaceTime Trend nResGrid\n",
      "10.0 Temp SpaceTime Trend nll\n",
      "10.0 Temp SpaceTime Trend sigmaOpt\n",
      "10.0 Temp SpaceTime Trend thetaLatOpt\n",
      "10.0 Temp SpaceTime Trend thetaLongOpt\n",
      "10.0 Temp SpaceTime Trend thetasOpt\n",
      "10.0 Temp SpaceTime Trend thetatOpt\n",
      "SpaceTimeNoTrendTemp*.mat\n",
      "file not found: /home/tyler/Kuusela-Stein/Data/Data/10.0/outliers_removed/NoTrend/Results/localMLESpaceTimeNoTrendTemp*.mat\n",
      "SpaceTimeTrend2Temp*.mat\n",
      "['/home/tyler/Kuusela-Stein/Data/Data/10.0/outliers_removed/Trend2/Results/localMLESpaceTimeTrend2TempMidOcean_5_20_10_02_2007_2018.mat']\n",
      "10.0 Temp SpaceTime Trend2 nResGrid\n",
      "10.0 Temp SpaceTime Trend2 nll\n",
      "10.0 Temp SpaceTime Trend2 sigmaOpt\n",
      "10.0 Temp SpaceTime Trend2 thetaLatOpt\n",
      "10.0 Temp SpaceTime Trend2 thetaLongOpt\n",
      "10.0 Temp SpaceTime Trend2 thetasOpt\n",
      "10.0 Temp SpaceTime Trend2 thetatOpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x7f26c0eff148>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allIters = [pressures, measurements, models, trends]\n",
    "grids = list(itertools.product(*allIters))\n",
    "\n",
    "docs = make_param_docs(grids)\n",
    "collName = 'ksParams'\n",
    "coll = create_collection('argo', collName, init_param_collection)\n",
    "coll.drop()\n",
    "coll.insert_many(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make anomaly collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ksTempAnom\n",
      "/home/tyler/Kuusela-Stein/Data/Data/10.0/outliers_removed/Trend/Results/anomalySpaceTrendTemp_at10.0dbar*.mat\n",
      "ksSpaceTempTrend\n",
      "num of anom mats: 144\n",
      "48\n",
      "48\n",
      "48\n",
      "/home/tyler/Kuusela-Stein/Data/Data/10.0/outliers_removed/NoTrend/Results/anomalySpaceNoTrendTemp_at10.0dbar*.mat\n",
      "ksSpaceTempNoTrend\n",
      "num of anom mats: 12\n",
      "4\n",
      "4\n",
      "4\n",
      "/home/tyler/Kuusela-Stein/Data/Data/10.0/outliers_removed/Trend2/Results/anomalySpaceTrend2Temp_at10.0dbar*.mat\n",
      "ksSpaceTempTrend2\n",
      "num of anom mats: 12\n",
      "4\n",
      "4\n",
      "4\n",
      "/home/tyler/Kuusela-Stein/Data/Data/10.0/outliers_removed/Trend/Results/anomalySpaceTimeTrendTemp_at10.0dbar*.mat\n",
      "ksSpaceTimeTempTrend\n",
      "num of anom mats: 12\n",
      "4\n",
      "4\n",
      "4\n",
      "/home/tyler/Kuusela-Stein/Data/Data/10.0/outliers_removed/NoTrend/Results/anomalySpaceTimeNoTrendTemp_at10.0dbar*.mat\n",
      "ksSpaceTimeTempNoTrend\n",
      "file not found: /home/tyler/Kuusela-Stein/Data/Data/10.0/outliers_removed/NoTrend/Results/anomalySpaceTimeNoTrendTemp_at10.0dbar*.mat\n",
      "/home/tyler/Kuusela-Stein/Data/Data/10.0/outliers_removed/Trend2/Results/anomalySpaceTimeTrend2Temp_at10.0dbar*.mat\n",
      "ksSpaceTimeTempTrend2\n",
      "num of anom mats: 12\n",
      "4\n",
      "4\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "def make_path_collection(pres, measurement, model, trend, param):\n",
    "    modelLabel = model.strip('localMLE')\n",
    "    presLabel = '_at{}dbar'.format(pres)\n",
    "    files = '{0}{1}{2}{3}{4}*.mat'.format(param, modelLabel, trend, measurement, presLabel)\n",
    "    path = os.path.join(kuuselaBase, pres,\\\n",
    "                        'outliers_removed', trend, 'Results',\\\n",
    "                        files)   \n",
    "    print(path)\n",
    "    return modelLabel, path\n",
    "\n",
    "def make_grid_collection(collName):\n",
    "    coll = create_collection('argo', collName, init_grid_collection)\n",
    "    coll.drop()\n",
    "    print(collName)\n",
    "    return coll\n",
    "\n",
    "def make_anomaly_collection():\n",
    "    allIters = [pressures, measurements, models, trends]\n",
    "    grids = list(itertools.product(*allIters))\n",
    "    param = 'anomaly'\n",
    "    dataVariable = 'predGrid'\n",
    "    collName = 'ksTempAnom'\n",
    "    coll = make_grid_collection(collName)\n",
    "    for pres, measurement, model, trend in grids:\n",
    "        modelLabel, path = make_path_collection(pres, measurement, model, trend, param) \n",
    "        anomMats = glob.glob(path)\n",
    "        gridName = 'ks' + model + measurement + trend\n",
    "        print(gridName)\n",
    "        if not anomMats:\n",
    "            print('file not found: {}'.format(path))\n",
    "            continue\n",
    "        print('num of anom mats: {}'.format(len(anomMats)))\n",
    "        for fileChunk in np.array_split(anomMats, 3):\n",
    "            docs = make_grid_docs(fileChunk, gridName, trend, param, dataVariable)\n",
    "            print(len(docs))\n",
    "            coll.insert_many(docs)\n",
    "    # make for express testing\n",
    "    testColl = create_collection('argo-express-test', collName, init_grid_collection)\n",
    "    testColl.drop()\n",
    "    testColl.insert_many(docs)\n",
    "    \n",
    "make_anomaly_collection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make mean collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ksTempMean\n",
      "/home/tyler/Kuusela-Stein/Data/Data/10.0/outliers_removed/Trend/Results/meanGridTrendTemp_at10.0dbar*.mat\n",
      "num of anom mats: 12\n",
      "ksMeanTempTrend\n",
      "4\n",
      "4\n",
      "4\n",
      "/home/tyler/Kuusela-Stein/Data/Data/10.0/outliers_removed/NoTrend/Results/meanGridNoTrendTemp_at10.0dbar*.mat\n",
      "num of anom mats: 12\n",
      "ksMeanTempNoTrend\n",
      "4\n",
      "4\n",
      "4\n",
      "/home/tyler/Kuusela-Stein/Data/Data/10.0/outliers_removed/Trend2/Results/meanGridTrend2Temp_at10.0dbar*.mat\n",
      "num of anom mats: 12\n",
      "ksMeanTempTrend2\n",
      "4\n",
      "4\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "def make_mean_collection():\n",
    "    trends\n",
    "    param = 'mean'\n",
    "    dataVariable = 'meanGrid'\n",
    "    \n",
    "    allIters = [pressures, measurements, trends]\n",
    "    grids = list(itertools.product(*allIters))\n",
    "    collName = 'ksTempMean'\n",
    "    coll = make_grid_collection(collName)\n",
    "    for pres, measurement, trend in grids:\n",
    "        modelLabel, path = make_path_collection(pres, measurement, '', trend, param+'Grid') \n",
    "        anomMats = glob.glob(path)\n",
    "        if not anomMats:\n",
    "            print('file not found: {}'.format(path))\n",
    "            continue\n",
    "        print('num of anom mats: {}'.format(len(anomMats)))\n",
    "        gridName = 'ksMean' + measurement + trend\n",
    "        print(gridName)\n",
    "        for fileChunk in np.array_split(anomMats, 3):\n",
    "            docs = make_grid_docs(fileChunk, gridName, trend, param, dataVariable)\n",
    "            print(len(docs))\n",
    "            coll.insert_many(docs)\n",
    "    # make for express testing\n",
    "    testColl = create_collection('argo-express-test', gridName, init_grid_collection)\n",
    "    testColl.drop()\n",
    "    testColl.insert_many(docs)\n",
    "make_mean_collection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Anomaly'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param.capitalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python AR",
   "language": "python",
   "name": "ar"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
