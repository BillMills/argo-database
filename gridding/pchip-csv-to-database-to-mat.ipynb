{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from scipy.io import savemat\n",
    "from datetime import datetime\n",
    "\n",
    "import pdb\n",
    "\n",
    "import psycopg2\n",
    "import sqlite3\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sqliteDb = \"/storage/kuusela-stein-intrep-profiles/pchip_profiles.db\"\n",
    "tableName = 'pchip'\n",
    "conn = sqlite3.connect(\"/storage/kuusela-stein-intrep-profiles/pchip_profiles.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x7f9b80192b20>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#conn = psycopg2.connect('postgresql://postgres:postgres@localhost:5432/atmos')\n",
    "#cur = conn.cursor()\n",
    "\n",
    "conn = sqlite3.connect(\"/storage/kuusela-stein-intrep-profiles/pchip_profiles.db\")\n",
    "\n",
    "conn.execute('''DROP TABLE IF EXISTS {};'''.format(tableName))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    smdf = pd.read_sql_query('SELECT * FROM {} LIMIT 10;'.format(tableName), conn)\n",
    "except Exception as err:\n",
    "    print(err)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/storage/kuusela-stein-intrep-profiles/iTempData_pres_10.0.csv\n",
      "/storage/kuusela-stein-intrep-profiles/iTempData_pres_20.0.csv\n",
      "/storage/kuusela-stein-intrep-profiles/iTempData_pres_30.0.csv\n",
      "/storage/kuusela-stein-intrep-profiles/iTempData_pres_50.0.csv\n",
      "/storage/kuusela-stein-intrep-profiles/iTempData_pres_60.0.csv\n",
      "/storage/kuusela-stein-intrep-profiles/iTempData_pres_70.0.csv\n",
      "/storage/kuusela-stein-intrep-profiles/iTempData_pres_100.0.csv\n",
      "/storage/kuusela-stein-intrep-profiles/iTempData_pres_110.0.csv\n",
      "/storage/kuusela-stein-intrep-profiles/iTempData_pres_120.0.csv\n",
      "/storage/kuusela-stein-intrep-profiles/iTempData_pres_150.0.csv\n",
      "/storage/kuusela-stein-intrep-profiles/iTempData_pres_160.0.csv\n",
      "/storage/kuusela-stein-intrep-profiles/iTempData_pres_170.0.csv\n",
      "/storage/kuusela-stein-intrep-profiles/iTempData_pres_220.0.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tyler/anaconda3/envs/argo/lib/python3.6/site-packages/numpy/lib/arraysetops.py:522: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/storage/kuusela-stein-intrep-profiles/iTempData_pres_240.0.csv\n",
      "/storage/kuusela-stein-intrep-profiles/iTempData_pres_40.0.csv\n",
      "/storage/kuusela-stein-intrep-profiles/iTempData_pres_80.0.csv\n"
     ]
    }
   ],
   "source": [
    "files = glob('/storage/kuusela-stein-intrep-profiles/iTempData_pres_*.0.csv')\n",
    "def convert_csv_to_sqlite(files):\n",
    "    for file in files:\n",
    "        print(file)\n",
    "        tdf = pd.read_csv(file, index_col=0)\n",
    "        tdf = tdf.drop('psal', axis=1)\n",
    "        psalFile = file.replace('Temp', 'Psal')\n",
    "        sdf = pd.read_csv(psalFile, index_col=0)\n",
    "        df = pd.merge(tdf, sdf[['profile_id', 'pres', 'psal']], how='outer', on=['profile_id', 'pres'])\n",
    "        df = df.drop_duplicates(subset=['profile_id', 'pres'])\n",
    "        df = df[df.lat != -89]\n",
    "        df.to_sql(tableName, conn, if_exists='append', index=False)\n",
    "        \n",
    "convert_csv_to_sqlite(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_pressure_level_df(conn, presLevel=20, tableName='pchip'):\n",
    "    try:\n",
    "        df = pd.read_sql_query('SELECT * FROM {0} WHERE pres = {1};'.format(tableName, presLevel), conn)\n",
    "        df = df.drop_duplicates(subset=['profile_id', 'pres'])\n",
    "        df = df[df['position_qc'].isin([1,2])]\n",
    "        df = df[df['date_qc'].isin([1,2])]\n",
    "    except Exception as err:\n",
    "        print(err)\n",
    "        raise(err)\n",
    "    return df\n",
    "\n",
    "def convert_lon(lon):\n",
    "    '''\n",
    "    converts from [-180, 180] to [20, 380]\n",
    "    '''\n",
    "    if lon < 20:\n",
    "        lon += 360\n",
    "    return lon\n",
    "\n",
    "def make_dict_for_mat(df, obs, minYear, maxYear):\n",
    "    df = df.dropna(how='any',axis=0, subset=[obs])\n",
    "    df = df.drop_duplicates(subset=['profile_id'])\n",
    "    df = df.drop_duplicates(subset=['lat', 'lon']) # need to have lat long be unique when making mask\n",
    "    df = df.sort_values(by=['lat', 'lon']) # sorting columns needed for binary search\n",
    "    df.date = pd.to_datetime(df.date.values)\n",
    "    df['year'] = df.date.apply(lambda x: x.year)\n",
    "    df['month'] = df.date.apply(lambda x: x.month)\n",
    "    df = df[(df['year'] >= minYear) & (df['year'] <= maxYear)]\n",
    "    df.date = df.date.apply(lambda x: x.strftime(\"%d-%b-%Y %H:%M:%S\"))\n",
    "    df['lon'] = df['lon'].apply(lambda lon: convert_lon(lon))\n",
    "    df = df[df[obs] != -999]\n",
    "    \n",
    "    df = df[[obs, 'profile_id', 'date', 'year', 'month', 'lat', 'lon']]\n",
    "    df.columns = ['obsProf', 'profFloatIDAggrSel', 'profJulDayAggrSel',\n",
    "                  'profYearAggrSel', 'profMonthAggrSel', 'profLatAggrSel', 'profLongAggrSel']\n",
    "    a_dict = {col_name : df[col_name].values for col_name in df.columns.values}\n",
    "\n",
    "    a_dict['profFloatIDAggrSel'] = a_dict['profFloatIDAggrSel'].astype(str)\n",
    "\n",
    "    return a_dict\n",
    "\n",
    "def make_file_name(presLevel, obs, minYear, maxYear, prefix='/storage/kuusela-stein-intrep-profiles/'):\n",
    "    fileName = prefix + 'prof'\n",
    "    fileName += str(obs).capitalize()\n",
    "    fileName += '_at{}dbar'.format(presLevel)\n",
    "    fileName += '_{0}_{1}'.format(minYear, maxYear)\n",
    "    fileName += '.mat'\n",
    "    return fileName\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/storage/kuusela-stein-intrep-profiles/profTemp_at10.0dbar_2007_2018.mat\n"
     ]
    }
   ],
   "source": [
    "minYear=2007\n",
    "maxYear=2018\n",
    "presLevel=20\n",
    "presLevels = [10.0]\n",
    "obs='temp'\n",
    "for presLevel in presLevels:\n",
    "    df = get_pressure_level_df(conn, presLevel)\n",
    "    if df.empty:\n",
    "        print('no presLevel []'.format(presLevel))\n",
    "        continue\n",
    "    presDict = make_dict_for_mat(df, obs, minYear, maxYear)\n",
    "    fileName = make_file_name(presLevel, obs, minYear, maxYear)\n",
    "    print(fileName)\n",
    "\n",
    "    savemat(fileName, presDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>pres</th>\n",
       "      <th>temp</th>\n",
       "      <th>profile_id</th>\n",
       "      <th>position_qc</th>\n",
       "      <th>date_qc</th>\n",
       "      <th>BASIN</th>\n",
       "      <th>psal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14-Jan-2007 20:05:00</td>\n",
       "      <td>-33.893</td>\n",
       "      <td>16.854</td>\n",
       "      <td>30.0</td>\n",
       "      <td>18.365000</td>\n",
       "      <td>1900112_44</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.493000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25-Jan-2007 10:05:00</td>\n",
       "      <td>-52.361</td>\n",
       "      <td>102.560</td>\n",
       "      <td>30.0</td>\n",
       "      <td>4.873531</td>\n",
       "      <td>1900382_100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>33.924000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>05-Jan-2007 10:12:00</td>\n",
       "      <td>-51.425</td>\n",
       "      <td>102.481</td>\n",
       "      <td>30.0</td>\n",
       "      <td>5.219000</td>\n",
       "      <td>1900382_98</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>33.921001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15-Jan-2007 10:15:00</td>\n",
       "      <td>-51.358</td>\n",
       "      <td>102.283</td>\n",
       "      <td>30.0</td>\n",
       "      <td>5.252000</td>\n",
       "      <td>1900382_99</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>33.938999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18-Jan-2007 02:54:00</td>\n",
       "      <td>-12.838</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>30.0</td>\n",
       "      <td>23.320000</td>\n",
       "      <td>1900394_89</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.706501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   date     lat      lon  pres       temp   profile_id  \\\n",
       "0  14-Jan-2007 20:05:00 -33.893   16.854  30.0  18.365000   1900112_44   \n",
       "1  25-Jan-2007 10:05:00 -52.361  102.560  30.0   4.873531  1900382_100   \n",
       "2  05-Jan-2007 10:12:00 -51.425  102.481  30.0   5.219000   1900382_98   \n",
       "3  15-Jan-2007 10:15:00 -51.358  102.283  30.0   5.252000   1900382_99   \n",
       "4  18-Jan-2007 02:54:00 -12.838   -0.024  30.0  23.320000   1900394_89   \n",
       "\n",
       "   position_qc  date_qc  BASIN       psal  \n",
       "0          1.0      1.0    1.0  35.493000  \n",
       "1          1.0      1.0   10.0  33.924000  \n",
       "2          1.0      1.0   10.0  33.921001  \n",
       "3          1.0      1.0   10.0  33.938999  \n",
       "4          1.0      1.0    1.0  36.706501  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  1, -1, ...,  1,  1,  1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "random_data = np.random.randn(50000,2)  * 20 + 20\n",
    "\n",
    "clf = IsolationForest( behaviour = 'new', max_samples=100, random_state = 1, contamination= 'auto')\n",
    "preds = clf.fit_predict(random_data)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['obsProf', 'profFloatIDAggrSel', 'profJulDayAggrSel', 'profLatAggrSel', 'profLongAggrSel'])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['18-Jan-2007 08:03:24', '25-Jan-2007 10:05:00',\n",
       "       '05-Jan-2007 10:12:00', '15-Jan-2007 10:15:00',\n",
       "       '08-Jan-2007 13:24:00', '18-Jan-2007 11:58:25',\n",
       "       '28-Jan-2007 12:05:29', '02-Jan-2007 17:02:10',\n",
       "       '12-Jan-2007 14:32:53', '22-Jan-2007 17:03:47'], dtype=object)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_dict['profJulDayAggrSel'][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(93, 10)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myDf[myDf['date_qc'].isnull()].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python argo",
   "language": "python",
   "name": "argo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
