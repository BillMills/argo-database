{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from scipy.io import savemat\n",
    "from datetime import datetime\n",
    "\n",
    "import pdb\n",
    "\n",
    "import psycopg2\n",
    "import sqlite3\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sqliteDb = \"/storage/kuusela-stein-intrep-profiles/pchip_profiles.db\"\n",
    "tableName = 'pchip'\n",
    "conn = sqlite3.connect(\"/storage/kuusela-stein-intrep-profiles/pchip_profiles.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x7f838aa9a1f0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#conn = psycopg2.connect('postgresql://postgres:postgres@localhost:5432/atmos')\n",
    "#cur = conn.cursor()\n",
    "\n",
    "conn = sqlite3.connect(\"/storage/kuusela-stein-intrep-profiles/pchip_profiles.db\")\n",
    "\n",
    "conn.execute('''DROP TABLE IF EXISTS {};'''.format(tableName))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution failed on sql 'SELECT * FROM pchip LIMIT 10;': no such table: pchip\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    smdf = pd.read_sql_query('SELECT * FROM {} LIMIT 10;'.format(tableName), conn)\n",
    "except Exception as err:\n",
    "    print(err)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/storage/kuusela-stein-intrep-profiles/iTempData_pres_10.0.csv\n",
      "/storage/kuusela-stein-intrep-profiles/iTempData_pres_100.0.csv\n"
     ]
    }
   ],
   "source": [
    "files = glob('/storage/kuusela-stein-intrep-profiles/iTempData_pres_10*.0.csv')\n",
    "def convert_csv_to_sqlite(files):\n",
    "    for file in files:\n",
    "        print(file)\n",
    "        tdf = pd.read_csv(file, index_col=0)\n",
    "        tdf = tdf.drop('psal', axis=1)\n",
    "        psalFile = file.replace('Temp', 'Psal')\n",
    "        sdf = pd.read_csv(psalFile, index_col=0)\n",
    "        df = pd.merge(tdf, sdf[['profile_id', 'pres', 'psal']], how='outer', on=['profile_id', 'pres'])\n",
    "        df = df.drop_duplicates(subset=['profile_id', 'pres'])\n",
    "        df = df[df.lat != -89]\n",
    "        df.to_sql(tableName, conn, if_exists='append', index=False)\n",
    "        \n",
    "convert_csv_to_sqlite(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_pressure_level_df(conn, presLevel=10, tableName='pchip'):\n",
    "    try:\n",
    "        df = pd.read_sql_query('SELECT * FROM {0} WHERE pres = {1};'.format(tableName, presLevel), conn)\n",
    "        df = df.drop_duplicates(subset=['profile_id', 'pres'])\n",
    "        df = df[df['position_qc'].isin([1,2])]\n",
    "        df = df[df['date_qc'].isin([1,2])]\n",
    "    except Exception as err:\n",
    "        print(err)\n",
    "        raise(err)\n",
    "    return df\n",
    "\n",
    "def convert_lon(lon):\n",
    "    '''\n",
    "    converts from [-180, 180] to [20, 380]\n",
    "    '''\n",
    "    if lon < 20:\n",
    "        lon += 360\n",
    "    return lon\n",
    "\n",
    "def make_dict_for_mat(df, obs, minYear, maxYear):\n",
    "    df = df.dropna(how='any',axis=0, subset=[obs])\n",
    "    df = df.drop_duplicates(subset=['profile_id'])\n",
    "    df = df.drop_duplicates(subset=['lat', 'lon']) # need to have lat long be unique when making mask\n",
    "    df = df.sort_values(by=['lat', 'lon']) # sorting columns needed for binary search\n",
    "    df.date = pd.to_datetime(df.date.values)\n",
    "    df['year'] = df.date.apply(lambda x: x.year)\n",
    "    df['month'] = df.date.apply(lambda x: x.month)\n",
    "    df = df[(df['year'] >= minYear) & (df['year'] <= maxYear)]\n",
    "    df.date = df.date.apply(lambda x: x.strftime(\"%d-%b-%Y %H:%M:%S\"))\n",
    "    df['lon'] = df['lon'].apply(lambda lon: convert_lon(lon))\n",
    "    df = df[df[obs] != -999]\n",
    "    \n",
    "    df = df[[obs, 'profile_id', 'date', 'year', 'month', 'lat', 'lon']]\n",
    "    df.columns = ['obsProf', 'profFloatIDAggrSel', 'profJulDayAggrSel',\n",
    "                  'profYearAggrSel', 'profMonthAggrSel', 'profLatAggrSel', 'profLongAggrSel']\n",
    "    a_dict = {col_name : df[col_name].values for col_name in df.columns.values}\n",
    "\n",
    "    a_dict['profFloatIDAggrSel'] = a_dict['profFloatIDAggrSel'].astype(str)\n",
    "\n",
    "    return a_dict\n",
    "\n",
    "def make_file_name(presLevel, obs, minYear, maxYear, prefix='/storage/kuusela-stein-intrep-profiles/'):\n",
    "    fileName = prefix + 'prof'\n",
    "    fileName += str(obs).capitalize()\n",
    "    fileName += '_at{}dbar'.format(str(presLevel))\n",
    "    fileName += '_{0}_{1}'.format(minYear, maxYear)\n",
    "    fileName += '.mat'\n",
    "    return fileName\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/storage/kuusela-stein-intrep-profiles/profTemp_at10.0dbar_2007_2018.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tyler/anaconda3/envs/argo/lib/python3.6/site-packages/scipy/io/matlab/miobase.py:414: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  arr[empties] = ' '\n"
     ]
    }
   ],
   "source": [
    "minYear=2007\n",
    "maxYear=2018\n",
    "presLevel=20\n",
    "presLevels = [10.0]\n",
    "obs='temp'\n",
    "for presLevel in presLevels:\n",
    "    df = get_pressure_level_df(conn, presLevel)\n",
    "    if df.empty:\n",
    "        print('no presLevel []'.format(presLevel))\n",
    "        continue\n",
    "    presDict = make_dict_for_mat(df, obs, minYear, maxYear)\n",
    "    fileName = make_file_name(presLevel, obs, minYear, maxYear)\n",
    "    print(fileName)\n",
    "\n",
    "    savemat(fileName, presDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "savemat(fileName, presDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['obsProf', 'profFloatIDAggrSel', 'profJulDayAggrSel', 'profYearAggrSel', 'profMonthAggrSel', 'profLatAggrSel', 'profLongAggrSel'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "presDict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  1, -1, ...,  1,  1,  1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "random_data = np.random.randn(50000,2)  * 20 + 20\n",
    "\n",
    "clf = IsolationForest( behaviour = 'new', max_samples=100, random_state = 1, contamination= 'auto')\n",
    "preds = clf.fit_predict(random_data)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['obsProf', 'profFloatIDAggrSel', 'profJulDayAggrSel', 'profLatAggrSel', 'profLongAggrSel'])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['18-Jan-2007 08:03:24', '25-Jan-2007 10:05:00',\n",
       "       '05-Jan-2007 10:12:00', '15-Jan-2007 10:15:00',\n",
       "       '08-Jan-2007 13:24:00', '18-Jan-2007 11:58:25',\n",
       "       '28-Jan-2007 12:05:29', '02-Jan-2007 17:02:10',\n",
       "       '12-Jan-2007 14:32:53', '22-Jan-2007 17:03:47'], dtype=object)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_dict['profJulDayAggrSel'][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(93, 10)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myDf[myDf['date_qc'].isnull()].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python argo",
   "language": "python",
   "name": "argo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
